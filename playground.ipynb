{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import copy\n",
    "import gymnasium as gym\n",
    "from typing import Generic, TypeVar, Tuple\n",
    "import numpy as np\n",
    "import torchrl\n",
    "import torch as th\n",
    "\n",
    "rl = torchrl.torchrl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GymEnv(env=CliffWalking-v0, batch_size=torch.Size([]), device=cpu)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check render modes\n",
    "env: rl.envs.EnvBase = rl.envs.GymEnv(\"CliffWalking-v0\")\n",
    "env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        observation: Tensor(shape=torch.Size([48]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "    batch_size=torch.Size([]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict = env.reset()\n",
    "tensordict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict['observation']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        action: Tensor(shape=torch.Size([4]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        next: TensorDict(\n",
       "            fields={\n",
       "                done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                observation: Tensor(shape=torch.Size([48]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "                reward: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "            batch_size=torch.Size([]),\n",
       "            device=cpu,\n",
       "            is_shared=False),\n",
       "        observation: Tensor(shape=torch.Size([48]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "    batch_size=torch.Size([]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def policy(tensordict, env=env):\n",
    "    tensordict.set(\"action\", env.action_spec.rand())\n",
    "    return tensordict\n",
    "policy(tensordict)\n",
    "tensordict_out = env.step(tensordict)\n",
    "tensordict_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensordict import TensorDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action 0\n",
      "tensor(36)\n",
      "tensor(24)\n",
      "action 1\n",
      "tensor(36)\n",
      "tensor(36)\n",
      "action 2\n",
      "tensor(36)\n",
      "tensor(36)\n",
      "action 3\n",
      "tensor(36)\n",
      "tensor(36)\n"
     ]
    }
   ],
   "source": [
    "def int_from_onehot(onehot: th.Tensor):\n",
    "    return th.argmax(onehot)\n",
    "\n",
    "def onehot_from_int(int, n=4, dtype=th.int64):\n",
    "    onehot = th.zeros(n, dtype=dtype)\n",
    "    onehot[int] = 1\n",
    "    return onehot\n",
    "\n",
    "def step_from_state(env, observation, action):\n",
    "    return env.step(TensorDict(source={\n",
    "        \"action\": action,\n",
    "        \"observation\": observation,\n",
    "    }, batch_size=[]))\n",
    "reset = env.reset()\n",
    "\n",
    "observation = onehot_from_int(0)\n",
    "# take random action 5 times\n",
    "\n",
    "for action in range(4):\n",
    "    env.reset() # this makes a difference!! env is stateful :(\n",
    "    print('action', action)\n",
    "    tensordict = step_from_state(env, reset['observation'], onehot_from_int(action))\n",
    "    print(int_from_onehot(tensordict['observation']))\n",
    "\n",
    "    print(int_from_onehot(tensordict['next']['observation']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.809636116027832\n"
     ]
    }
   ],
   "source": [
    "# benchmark deepcopy of env\n",
    "import time\n",
    "env = rl.envs.GymEnv(\"CliffWalking-v0\")\n",
    "env.reset()\n",
    "start = time.time()\n",
    "for i in range(1000):\n",
    "    env = copy.deepcopy(env)\n",
    "\n",
    "print(time.time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.131824875017628"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# benchmakr with timeit\n",
    "import timeit\n",
    "timeit.timeit('copy.deepcopy(env)', globals=globals(), number=1000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alphazero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
